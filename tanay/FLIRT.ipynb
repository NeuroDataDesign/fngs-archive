{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import os\n",
    "from nibabel.testing import data_path\n",
    "\n",
    "def no_transform(dirname):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "        \n",
    "    brain = np.random.randint(low=50, high=60, size=20*20, dtype=np.int16).reshape((20,20))\n",
    "    #brain = np.arange(50*50*50, dtype=np.int16).reshape((50,50,50))\n",
    "    identity = np.diag([1,1,1,1])\n",
    "    brainimg = nb.Nifti1Image(brain, affine=identity)\n",
    "\n",
    "    nb.save(brainimg, dirname + \"/inp.nii.gz\")\n",
    "    nb.save(brainimg, dirname + \"/ref.nii.gz\")\n",
    "    np.savetxt(dirname + \"/correctaffine.txt\", identity)\n",
    "\n",
    "def translation(dirname):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "    #brain = np.random.randint(low=50, high=60, size=50*50*50, dtype=np.int16).reshape((50,50,50))\n",
    "    #brain = 50*np.ones((100,100), dtype=np.int16)\n",
    "    brain = np.random.randint(low=30,high=70,size=100*100, dtype=np.int16).reshape((100,100))\n",
    "    displacement = np.random.randint(low=20, high=40, size=1, dtype=np.int16)\n",
    "    displacement = displacement[0]\n",
    "    #zeros = np.zeros((displacement,50,50),dtype=np.int16)\n",
    "    zeros = np.zeros((displacement,100),dtype=np.int16)\n",
    "    identity = np.diag([1,1,1,1])\n",
    "\n",
    "    brainmod = np.vstack((zeros, brain))\n",
    "    brainimg = nb.Nifti1Image(brainmod, affine=identity)\n",
    "    nb.save(brainimg, dirname + \"/inp.nii.gz\")\n",
    "\n",
    "    brainmod = np.vstack((brain, zeros))\n",
    "    brainimg = nb.Nifti1Image(brainmod, affine=identity)\n",
    "    nb.save(brainimg, dirname + \"/ref.nii.gz\")\n",
    "\n",
    "    identity[0,3] = displacement\n",
    "    np.savetxt(dirname + \"/correctaffine.txt\", identity)\n",
    "\n",
    "def scaling(dirname):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "    brain = 50*np.ones((50,50,50), dtype=np.int16)\n",
    "    #brain = 50*np.ones((50,50), dtype=np.int16)\n",
    "    identity = np.diag([1,1,1,1])\n",
    "    factor = np.random.randint(low=10, high=40, size=1, dtype=np.int16)\n",
    "    f = factor[0]\n",
    "\n",
    "    brainmod = np.lib.pad(brain, ((f,f),(f,f),(f,f)), 'constant', constant_values=(0))\n",
    "    #brainmod = np.lib.pad(brain, ((f,f),(f,f)), 'constant', constant_values=(0))\n",
    "    brainimg = nb.Nifti1Image(brainmod, affine=identity)\n",
    "    nb.save(brainimg, dirname + \"/inp.nii.gz\")\n",
    "\n",
    "    f=f-1\n",
    "    brainmod = np.lib.pad(brain, ((f,f),(f,f),(f,f)), 'constant', constant_values=(50))\n",
    "    #brainmod = np.lib.pad(brain, ((f,f),(f,f)), 'constant', constant_values=(50))\n",
    "    brainmod = np.lib.pad(brainmod, ((1,1),(1,1),(1,1)), 'constant', constant_values=(0))\n",
    "    #brainmod = np.lib.pad(brainmod, ((1,1),(1,1)), 'constant', constant_values=(0))\n",
    "    brainimg = nb.Nifti1Image(brainmod, affine=identity)\n",
    "    nb.save(brainimg, dirname + \"/ref.nii.gz\")\n",
    "\n",
    "def rotation(dirname):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "    identity = np.diag([1,1,1,1])\n",
    "    brain = np.arange(50*50, dtype=np.int16).reshape((50,50))\n",
    "    brainimg = nb.Nifti1Image(brain, affine=identity)\n",
    "    nb.save(brainimg, dirname + \"/inp.nii.gz\")\n",
    "\n",
    "    numrots = np.random.randint(low=1,high=4,size=1, dtype=np.int16)\n",
    "    numrots = numrots[0]\n",
    "    brainmod = np.rot90(brain, numrots)\n",
    "    brainimg = nb.Nifti1Image(brainmod, affine=identity)\n",
    "    nb.save(brainimg, dirname + \"/ref.nii.gz\")\n",
    "\n",
    "    if (numrots == 1):\n",
    "        identity[0,0] = 0\n",
    "        identity[1,1] = 0\n",
    "        identity[0,1] = 1\n",
    "        identity[1,0] = -1\n",
    "        identity[1,3] = 49\n",
    "    if (numrots == 2):\n",
    "        identity[0,0] = -1\n",
    "        identity[1,1] = -1\n",
    "        identity[0,1] = 0\n",
    "        identity[1,0] = 0\n",
    "        identity[1,3] = 49\n",
    "        identity[0,3] = 49\n",
    "    if (numrots == 3):\n",
    "        identity[0,0] = 0\n",
    "        identity[1,1] = 0\n",
    "        identity[0,1] = -1\n",
    "        identity[1,0] = 1\n",
    "        identity[0,3] = 49\n",
    "    np.savetxt(dirname + \"/correctaffine.txt\", identity)\n",
    "\n",
    "def non_linear(dirname):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "    identity = np.diag([1,1,1,1])\n",
    "    #brain = np.arange(50*50, dtype=np.int16).reshape((50,50))\n",
    "    brain = np.random.randint(low=10, high=40, size=50*50, dtype=np.int16).reshape((50,50))\n",
    "    brainimg = nb.Nifti1Image(brain, affine=identity)\n",
    "    nb.save(brainimg, dirname + \"/inp.nii.gz\")\n",
    "\n",
    "    a = np.random.randint(low=10, high=40, size=1, dtype=np.int16)[0]\n",
    "    b = np.random.randint(low=10, high=40, size=1, dtype=np.int16)[0]\n",
    "    n = 50\n",
    "    r = np.random.randint(low=10, high=40, size=1, dtype=np.int16)[0]\n",
    "    y,x = np.ogrid[-a:n-a, -b:n-b]\n",
    "    mask = x*x + y*y <= r*r\n",
    "\n",
    "    brain[mask] = 0\n",
    "    brainimg = nb.Nifti1Image(brain, affine=identity)\n",
    "    nb.save(brainimg, dirname + \"/ref.nii.gz\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #rotation(\"1\")\n",
    "    \n",
    "    for i in range(3):\n",
    "        no_transform(str(i))\n",
    "    for i in range(3,13):\n",
    "        translation(str(i))\n",
    "    for i in range(13,23):\n",
    "        scaling(str(i))\n",
    "    for i in range(23,26):\n",
    "        rotation(str(i))\n",
    "    for i in range(26,36):\n",
    "        non_linear(str(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each function above generates a simulation of two \"brain\" files: an input and a reference. Each simulation represents one type of linear transformation, meaning the input data should be some linear transformation of the reference data. \n",
    "\n",
    "The no_transformation simulation should produce two identical square matrices of random numbers. \n",
    "\n",
    "The translation simulation should produce an input square matrix of random intensities, and the reference matrix should look like a right-shifted version of the input.\n",
    "\n",
    "The scaling simulation should produce a small input square matrix of equal intensity, and the reference matrix should be a bigger square matrix with the same intensity.\n",
    "\n",
    "The rotation simulation should produce an input square matrix of uniformly increasing intensity, and the reference matrix should be a rotated version of the input.\n",
    "\n",
    "The non_linear simulation should produce an input square matrix of random intensities, and the reference matrix should be the same as the input except with a circular chunk cut out, making the reference a non-linear transformation of the input.\n",
    "\n",
    "Below are some of the simulation data produced. The left image in each pair shows the input and the right image shows the reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![no transformation](flirt_pics/none0.jpg)\n",
    "![no transformation](flirt_pics/none1.jpg)\n",
    "![no transformation](flirt_pics/none2.jpg)\n",
    "![translation](flirt_pics/trans3.jpg)\n",
    "![translation](flirt_pics/trans6.jpg)\n",
    "![translation](flirt_pics/trans10.jpg)\n",
    "![scaling](flirt_pics/scale13.jpg)\n",
    "![scaling](flirt_pics/scale15.jpg)\n",
    "![scaling](flirt_pics/scale17.jpg)\n",
    "![rotation](flirt_pics/rot23.jpg)\n",
    "![rotation](flirt_pics/rot24.jpg)\n",
    "![non linear](flirt_pics/nlin26.jpg)\n",
    "![non linear](flirt_pics/nlin28.jpg)\n",
    "![non linear](flirt_pics/nlin30.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the simulation data looks as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudocode\n",
    "\n",
    "Linear registration works through the following general steps:\n",
    "\n",
    "1) Initial search: perform a cursory pass through some transformation combinations to find one that results in a cost function value believed to be close to optimal.\n",
    "\n",
    "2) While possible, use gradient descent to find a new combinations of transformations with a cost value closer to optimal.\n",
    "\n",
    "3) Terminate when local minimum for cost function is reached.\n",
    "\n",
    "The algorithm code is not provided because it is an external tool.\n",
    "\n",
    "The FLIRT algorithm should perform very well on the \"easy\" simulations because they are all simple linear transformations, which is what FLIRT is designed for. The error should be very low. However, the algorithm should not perform well on the \"hard\" simulations because they are non-linear transformations, which is absolutely not what FLIRT is designed for. The error should be very high.\n",
    "\n",
    "Below we see the results from performing the algorithm on the simulation data generated above. Each image represents the \"registered\" data, which should match the \"reference\" images from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![flirted](flirt_pics/flirted0.jpg)\n",
    "![flirted](flirt_pics/flirted1.jpg)\n",
    "![flirted](flirt_pics/flirted2.jpg)\n",
    "![flirted](flirt_pics/flirted3.jpg)\n",
    "![flirted](flirt_pics/flirted6.jpg)\n",
    "![flirted](flirt_pics/flirted10.jpg)\n",
    "![flirted](flirt_pics/flirted13.jpg)\n",
    "![flirted](flirt_pics/flirted15.jpg)\n",
    "![flirted](flirt_pics/flirted17.jpg)\n",
    "![flirted](flirt_pics/flirted23.jpg)\n",
    "![flirted](flirt_pics/flirted24.jpg)\n",
    "![flirted](flirt_pics/flirted26.jpg)\n",
    "![flirted](flirt_pics/flirted28.jpg)\n",
    "![flirted](flirt_pics/flirted30.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the linear transformations, we will use the following quantitative metric: sum of elements in difference matrix (between correct and registered affine matrix). Basically, we will take the difference between the correct affine matrix and the output of the linear registration, and then the sum of the elements in this matrix will be our error. \n",
    "\n",
    "For the non-linear transformations, we will use the following quantitative metric: we will compare the reference and registered data by taking the difference between the two matrices and summing the elements in the difference matrix. This will give us the number of pixels that were mis-registered.\n",
    "\n",
    "Code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import os\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    errors = []\n",
    "    for i in range(26):\n",
    "        dirname = str(i)\n",
    "        correct = np.loadtxt(dirname + \"/correctaffine.txt\")\n",
    "        estimate = np.loadtxt(dirname + \"/flirted.mat\")\n",
    "        error = np.sum(np.absolute(correct - estimate))\n",
    "        errors.append(error)\n",
    "\n",
    "    for i in range(26,36):\n",
    "        flirted = nb.load(str(i) + \"/flirted.nii.gz\").get_data()\n",
    "        correct = nb.load(str(i) + \"/ref.nii.gz\").get_data()\n",
    "\n",
    "        flirted[flirted > 1] = 1\n",
    "        correct[correct > 1] = 1\n",
    "        error = np.sum(np.absolute(correct - flirted))\n",
    "        errors.append(error)\n",
    "    print errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.0, 0.0, 0.0, 1.550825195960003, 3.422254708859532, 11.980898569719997, 7.9705488077200028, 7.9201462880400024, 7.9358725125999987, 17.886743152900003, 1.5286875421199995, 1.033651326572408, 7.9116499097000021, 2.818713867125501, 3.187876099440456, 1.478484436311636, 2.833005868538394, 1.4267679668403832, 3.612968803025274, 2.6988117453018945, 1.7665954798872798, 3.830883126957, 3.231849615262577, 3.5460977669955334, 0.74573975247713831, 0.74573975247713831, 2255, 2172, 1009, 317, 1944, 1802, 2440, 1696, 1007, 2163]\n",
    "\n",
    "The numbers above represent the error from each simulation trial. We will visualize population performance by plotting the error from each trial in a scatter plot. We will compute the overall population performance by taking the average error of all the trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = range(0,3)\n",
    "plt.scatter(x, errors[0:3], c='b', s=40, label='no transform')\n",
    "x = range(23,26)\n",
    "plt.scatter(x, errors[23:26], c='r', s=40, label='rotation')\n",
    "x = range(3,13)\n",
    "plt.scatter(x, errors[3:13], c='g', s=40, label='translation')\n",
    "x = range(13,23)\n",
    "plt.scatter(x, errors[13:23], c='y', s=40, label='scaling')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Errors')\n",
    "plt.savefig(\"errors1.png\")\n",
    "plt.cla()\n",
    "\n",
    "x = range(0,10)\n",
    "plt.scatter(x, errors[26:], s=40, label='non linear')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Errors')\n",
    "plt.savefig(\"errors2.png\")\n",
    "plt.cla()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![error](flirt_pics/errors1.jpg)\n",
    "![error](flirt_pics/errors2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noneavg = np.mean(errors[0:3])\n",
    "transavg = np.mean(errors[3:13])\n",
    "scaleavg = np.mean(errors[13:23])\n",
    "rotavg = np.mean(errors[23:26])\n",
    "nlinavg = np.mean(errors[26:36])\n",
    "\n",
    "print \"No transform: \", noneavg\n",
    "print \"Translation: \", transavg\n",
    "print \"Scaling: \", scaleavg\n",
    "print \"Rotation: \", rotavg\n",
    "print \"Non linear: \", nlinavg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code computes the average error for each simulation type, shown below:\n",
    "\n",
    "No transform:  0.0  \n",
    "Translation:  7.03717370471  \n",
    "Scaling:  2.10241035455  \n",
    "Rotation:  1.50942092533  \n",
    "Non linear:  1680.5\n",
    "\n",
    "As we can see, the algorithm performs very well on the linear transformations and very poorly on the non-linear transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real data\n",
    "\n",
    "Now we show the results of the algorithm on real data. We have two datasets: BNU2 and SWU4. Our reference is the MNI152_2mm brain scan. Below, we show the result of registering one brain from each dataset to the referecen.\n",
    "\n",
    "The left images are the reference, the middle images are the preprocessed input brain, and the right images are the registered brain.\n",
    "\n",
    "BNU2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![real data](flirt_pics/realdata.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWU4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![real data](flirt_pics/realdata2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above images, we can see that performing FLIRT does indeed make the input brains appear similar to the MNI reference brain. In order to evaluate the usefulness of the algorithm, we will have to quantify its performance on real data. We can do this by seeing if perform FLIRT improves dataset-wide discriminability:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
